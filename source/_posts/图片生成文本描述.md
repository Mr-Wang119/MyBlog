---
title: 图片生成文本描述
date: 2019-10-26 23:23:19
tags: 
- 图像特征提取
- 语言模型
- 项目
categories: 图像

---

> https://www.jiqizhixin.com/articles/2017-11-15-2

## 1. 传统方法

###        生成描述模板: 基于目标检测和属性发现（attribute discovery）的结果进行填充；

###        数据库检索相似图像

<!--more-->

## 2. 模型

### 特征提取模型

用作特征提取子模型的通常是深度卷积神经网络（CNN）。这种网络可以在图像描述数据集中的图像上直接训练。

或者可以使用预训练的模型（比如用于图像分类的当前最佳的模型），或者也可以使用混合方法，即使用预训练的模型并根据实际问题进行微调。

使用为 ILSVRC 挑战赛在 ImageNet 数据集上开发的表现最好的模型是很常见的做法，比如 Oxford Vision Geometry Group 模型，简称 VGG。

### 语言模型

对于图像描述，语言模型这种神经网络可以基于网络提取出的特征预测描述中的词序列并根据已经生成的词构建描述。

常用的方法是使用循环神经网络作为语言模型，比如长短期记忆网络（LSTM）。每个输出时间步骤都会在序列中生成一个新词。

然后每个生成的词都会使用一个词嵌入（比如 word2vec）进行编码，该编码会作为输入被传递给解码器以生成后续的词。

对该模型的一种改进方法是为输出序列收集词在词汇库中的概率分布并搜索它以生成多个可能的描述。这些描述可以根据似然（likelihood）进行评分和排序。常见的方式是使用波束搜索（Beam Search）进行这种搜索。

语言模型可以使用从图像数据集提取出的预计算的特征单独训练得到；也可以使用特征提取网络或某些组合方法来联合训练得到。

### 编码器-解码器

这种架构原本是为机器翻译开发的，其中输入的序列（比如法语）会被一个编码器网络编码成固定长度的向量。然后一个分立的解码器网络会读取这些编码并用另一种语言（比如英语）生成输出序列。

除了能力出色外，这种方法的好处是可以在该问题上训练单个端到端模型。

当将该方法用于图像描述时，编码器网络使用了深度卷积神经网络，解码器网络则是 LSTM 层的堆叠。

> #### 注意力机制
>
> 编码器-解码器的一个局限性是使用了单个固定长度的表征来保存提取出的特征。
>
> 在机器翻译中，这个问题通过在更丰富的编码上开发的注意机制而得到了解决，从而让解码器可以学习在生成翻译中的每个词时应该注意哪里。
>
> 这种方法也已经被用于改进用于图像描述的编码器-解码器架构的表现水平——让解码器可以学习在生成描述中每个词时应该关注图像中的哪些部分。